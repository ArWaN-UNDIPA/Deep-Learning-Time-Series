# -*- coding: utf-8 -*-
"""Deep-ConvLSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nJ61biiyrAnpMTW8y9bs0ajyDGQ1vsDC
"""

from google.colab import drive
drive.mount('/content/drive')

#import torch
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from matplotlib import rc
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
from torch import nn, optim
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error #as mae
from sklearn.metrics import r2_score
from statistics import mode
#from sklearn.preprocessing import MinMaxScaler
from pandas.plotting import register_matplotlib_converters
import copy
import os
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf # version tensorflow==2.4.0
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional
import random
random.seed(500)
import scipy.stats
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import Conv3D
from keras.layers import ConvLSTM2D
from keras.layers import ConvLSTM3D
from keras.layers import BatchNormalization

#PreProcessing

import os
os.chdir(r"/content/drive/My Drive")

#Test dataset from LSTNet
from google.colab import files
uploaded = files.upload()

#datasets = pd.read_csv('electricity datasets.csv',encoding='ISO-8859-1')
#datasets
#datasets = pd.read_csv('ETTh1.csv')
#datasets = pd.read_csv('ETTh2.csv')
#datasets = pd.read_csv('ETTm1.csv')
#datasets = pd.read_csv('ETTm2.csv')
#datasets = pd.read_csv('energydata_complete.csv')
datasets = pd.read_csv('exchange_rate.csv')
datasets

#datasets['date'] = pd.to_datetime(datasets['date']).dt.date
datasets['date'] = pd.to_datetime(datasets['date'],format='mixed').dt.date

datasets

datasets['date']=pd.to_datetime(datasets['date'])

datasets.index = datasets.pop('date')

datasets

#Energy dataset
#target = datasets['RH_out']
#target =pd.DataFrame(target,columns=['RH_out'])
#target
#ETT dataset
#target = datasets['OT']
#target =pd.DataFrame(target,columns=['OT'])
#target
#ExchangeRate dataset
target = datasets['OT']
target =pd.DataFrame(target,columns=['OT'])
target

#For ETTm Dataset
#test_data_size = 13936
#For ETTh Dataset
#test_data_size = 3484
#For Energy Dataset
#test_data_size = 3947
#For Exchange Dataset
test_data_size = 3484
train_data_target = target[:-test_data_size]
test_data_target = target[-test_data_size:]

print("Len Train Data Target",train_data_target.shape)
print("Len Test Data Target",test_data_target.shape)

scaler = MinMaxScaler(feature_range=(-1, 1))
train_data_target = scaler.fit_transform(train_data_target)
test_data_target = scaler.fit_transform(test_data_target)

def create_sequences(data, seq_length):
    xs = []
    ys = []

    for i in range(len(data)-seq_length-1):
        x = data[i:(i+seq_length)]
        y = data[i+seq_length]
        xs.append(x)
        ys.append(y)

    return np.array(xs), np.array(ys)

seq_length = 24
#Target
X_train_target, y_train_target = create_sequences(train_data_target, seq_length)
X_test_target, y_test_target = create_sequences(test_data_target, seq_length)
X_train_target = torch.from_numpy(X_train_target).float()
y_train_target = torch.from_numpy(y_train_target).float()
X_test_target = torch.from_numpy(X_test_target).float()
y_test_target = torch.from_numpy(y_test_target).float()

print("X train target",X_train_target.shape)
print("y train target",y_train_target.shape)
print("-------------------------------------")

print("X test target",X_test_target.shape)
print("y test target",y_test_target.shape)
print("-------------------------------------")

class DeepConvLSTM:
  def __init__(self, epochs, batch_size, learning_rate,beta_1,beta_2):
    self.epochs = epochs
    self.batch_size = batch_size
    self.learning_rate = learning_rate
    self.beta_1 = beta_1
    self.beta_2 = beta_2

  def Tensor(self):
    self.X_target = np.array(X_train_target)
    self.Y_target = np.array(y_train_target)
    self.test_X_target = np.array(X_test_target)
    self.test_Y_target = np.array(y_test_target)
    #self.test_Y_ConvLSTM = np.array(y_test_target)
    #test_X_ConvLSTM = np.array(X_test_target)
    #test_Y_ConvLSTM = np.array(y_test_target)

  def ConvLSTM(self):
    #Construct Model
    model_ConvLSTM = tf.keras.models.Sequential([
        tf.keras.layers.Conv1D(filters=32, kernel_size=3,
                               strides=1, padding="causal",
                               activation="relu",
                              input_shape=(X_train_target.shape[1],X_train_target.shape[2])),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8,return_sequences=True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(4,return_sequences=False)),
        tf.keras.layers.Dense(1),
        tf.keras.layers.Lambda(lambda x: x * 100)]) #original value 200
    #optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9) #3e-4,1e-5
    #model_TargetConvLSTM.compile(loss=tf.keras.losses.Huber(),optimizer=optimizer,metrics=['mse'])
    optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate, beta_1=self.beta_1, beta_2=self.beta_2,amsgrad=True)
    model_ConvLSTM.compile(loss='mean_squared_error', optimizer = optimizer)
    #Train The Model
    ConvLSTM = model_ConvLSTM.fit(self.X_target,self.Y_target,shuffle = False,epochs=self.epochs,batch_size=self.batch_size,validation_split=0.2,verbose=1)
    #Predict
    self.y_pred_ConvLSTM = model_ConvLSTM.predict(self.test_X_target)[:24] #[:720] #[:336] #[:192] #[:96]
    self.final_predict = self.y_pred_ConvLSTM.flatten()[:24]
    self.test_Y_target = self.test_Y_target.flatten()[:24]

    #def Ploting_train(self):
    #  pass
  def Final_predict(self):
    #self.y_pred_BiLSTM = self.y_pred_BiLSTM.flatten()[:720] #[:336] #[:192] #[:96]      # Predict AQI using ConvLSTM
    self.y_pred_ConvLSTM = self.y_pred_ConvLSTM.flatten()[:24] #[:720] #[:336] #[:192] #[:96]          # predict AQI using Bi-LSTM
    #self.y_pred_StakedLSTM = self.y_pred_StakedLSTM.flatten()[:720] #[:336] #[:192] #[:96]            # Predict ExFactor
    #y_pred_StackedGRU = y_pred_StackedGRU.flatten()  # Predict Ratio
    #y_pred_StakedLSTM = y_pred_StakedLSTM.flatten()
    #self.test_Y_target = self.test_Y_target.flatten()[:720] #[:336] #[:192] #[:96]
    #yHat = (y_pred_ConvLSTM + y_pred_BiLSTM + y_pred_BiGRU + y_pred_StackedGRU) / 4
    #self.yHat = (self.y_pred_BiLSTM + self.y_pred_ConvLSTM + self.y_pred_StakedLSTM) / 3
    #yHat2 = (((y_pred_ConvLSTM + y_pred_BiLSTM + y_pred_BiGRU) / 3 ) + y_pred_StackedGRU)/2
    #yHat3 = (((y_pred_ConvLSTM + y_pred_BiLSTM + y_pred_StackedGRU) / 3 ) + y_pred_BiGRU)/2

  def Dataframe(self):
    self.result = pd.DataFrame(data={'Actual AQI':self.test_Y_target,'Deep ConvLSTM':self.final_predict})
    return self.result

  def smape(self,a, f):
    return 1/len(self.a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)

  def matrik_error(self):
    self.mse_ensemble = mean_squared_error(self.result['Actual AQI'], self.result['Deep ConvLSTM'])
    self.mae_ensemble = mean_absolute_error(self.result['Actual AQI'], self.result['Deep ConvLSTM'])
    #smape_ensemble = smape(first_strategy_result['Actual AQI'], first_strategy_result['Ensemble Methods'])
    self.r2_ensemble = r2_score(self.result['Actual AQI'], self.result['Deep ConvLSTM'],multioutput='variance_weighted')

  def evaluation(self):
    print("MSE First Strategy",self.mse_ensemble)
    print("MAE First Strategy",self.mae_ensemble)
    #print("Smape First Strategy",smape_ensemble)
    print("R2 First Strategy",self.r2_ensemble)

Model = DeepConvLSTM(12,8,0.0001,0.9,0.99)
Model.Tensor()
#Model.BiLSTM()
Model.ConvLSTM()
#Model.StackedLSTM()
#Model.Final_predict()
Model.Dataframe()
Model.matrik_error()
Model.evaluation()

n = 17
print(type(n))
pi = 3.14159265
print(type(pi))
messages = 'ini adalah string'
print(type(messages))
tes = 123