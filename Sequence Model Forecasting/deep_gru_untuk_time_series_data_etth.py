# -*- coding: utf-8 -*-
"""Deep GRU Untuk Time Series Data ETTh.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BFYOgyP-AQkQ2Dl3jB32iLU7Y1dycdGK
"""

from google.colab import drive
drive.mount('/content/drive')

#import torch
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from matplotlib import rc
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from statistics import mode
import copy
import os
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
import torch
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional
import random
import scipy.stats
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import Conv3D
from keras.layers import ConvLSTM2D
from keras.layers import ConvLSTM3D
from keras.layers import BatchNormalization
from statistics import mode
import inspect

random.seed(2505)

#PreProcessing

import os
os.chdir(r"/content/drive/My Drive")

from google.colab import files
uploaded = files.upload()

#datasets = pd.read_csv('ETTh1.csv')
#datasets = pd.read_csv('ETTh2.csv')
#datasets = pd.read_csv('ETTm1.csv')
#datasets = pd.read_csv('ETTm2.csv')
#datasets = pd.read_csv('new_Shanghai AQI and Wheather 2014-2021.csv')
datasets = pd.read_csv('energydata_complete.csv')
datasets

datasets['date'] = pd.to_datetime(datasets['date'],format='mixed').dt.date
#datasets['date'] = pd.to_datetime(datasets['date']).dt.date
datasets

datasets['date']=pd.to_datetime(datasets['date'])

datasets.index = datasets.pop('date')

datasets

#ETT Dataset
#target = datasets['OT']
#target =pd.DataFrame(target,columns=['OT'])
#AQI Dataset
#target = datasets['AQI']
#target =pd.DataFrame(target,columns=['AQI'])
#Energy Dataset
target = datasets['RH_out']
target =pd.DataFrame(target,columns=['RH_out'])

## PreProcessing

target = target[np.isfinite(target).all(1)]

#ETT Dataset
#test_data_size = 3484
#test_data_size = 13936

#AQI Dataset
#test_data_size = 500

#Energy Dataset
test_data_size = 3947

#Target
train_data_target = target[:-test_data_size]
test_data_target = target[-test_data_size:]

print("Len Train Data Target",train_data_target.shape)
print("Len Test Data Target",test_data_target.shape)

scaler = MinMaxScaler(feature_range=(-1, 1))
#Target
train_data_target = scaler.fit_transform(train_data_target)
test_data_target = scaler.fit_transform(test_data_target)

## Transform to Time Series

def create_sequences(data, seq_length):
    xs = []
    ys = []

    for i in range(len(data)-seq_length-1):
        x = data[i:(i+seq_length)]
        y = data[i+seq_length]
        xs.append(x)
        ys.append(y)

    return np.array(xs), np.array(ys)

#ETT Dataset
#seq_length = 24
#AQI Dataset
#seq_length = 30
#Energy Dataset
seq_length = 24
#Target
X_train_target, y_train_target = create_sequences(train_data_target, seq_length)
X_test_target, y_test_target = create_sequences(test_data_target, seq_length)
X_train_target = torch.from_numpy(X_train_target).float()
y_train_target = torch.from_numpy(y_train_target).float()
X_test_target = torch.from_numpy(X_test_target).float()
y_test_target = torch.from_numpy(y_test_target).float()

print("X train target",X_train_target.shape)
print("y train target",y_train_target.shape)
print("-------------------------------------")

print("X test target",X_test_target.shape)
print("y test target",y_test_target.shape)
print("-------------------------------------")

#Target
X_target = np.array(X_train_target)
Y_target = np.array(y_train_target)

## Bi-GRU Model

class BiGRU:
  def __init__(self, epochs, batch_size, learning_rate,beta_1,beta_2):
    self.epochs = epochs
    self.batch_size = batch_size
    self.learning_rate = learning_rate
    self.beta_1 = beta_1
    self.beta_2 = beta_2

  def tensor(self):
    self.test_X_target_modelBiGRU = np.array(X_test_target)
    self.test_Y_target_modelBiGRU = np.array(y_test_target)
    self.test_Y_target = np.array(y_test_target)

  def model_BiGRU(self):
    #Let's build Bi-GRU
    modelBiGRU = keras.Sequential()
    #Add a GRU layer with 3 units.
    modelBiGRU.add(Bidirectional(layers.GRU(512,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True,
                     #input_shape=(X_train_target.shape[1], X_train_target.shape[2]))))
                     input_shape=(X_train_target.shape[1], X_train_target.shape[2]))))
    modelBiGRU.add(Bidirectional(layers.GRU(256,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(128,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(64,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(32,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(16,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(8,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(5,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=True)))
    modelBiGRU.add(Bidirectional(layers.GRU(3,
                     activation = "tanh",
                     recurrent_activation = "sigmoid",
                     return_sequences=False)))
    modelBiGRU.add(layers.Dropout(rate=0.01))
    #Add a Dense layer with 1 units (Since we are doing a regression task.
    modelBiGRU.add(layers.Dense(1))
    optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate, beta_1=self.beta_1, beta_2=self.beta_2,amsgrad=False)
    modelBiGRU.compile(loss='mean_squared_error', optimizer = optimizer)
    self.historymodelBiGRU = modelBiGRU.fit(X_target,Y_target, shuffle = False,epochs=self.epochs,batch_size=self.batch_size,validation_split=0.2,verbose=1)
    self.y_pred_modelBiGRU = modelBiGRU.predict(self.test_X_target_modelBiGRU)[:96] #[:96]
    return

  def predict(self):
    self.y_pred_target_modelBiGRU = self.y_pred_modelBiGRU.flatten()[:96] #[:96]
    self.y_test_target = self.test_Y_target_modelBiGRU.flatten()[:96] #[:96]

  def dataframe(self):
    self.result = pd.DataFrame(data={'Actual Value':self.y_test_target,'Bi-GRU':self.y_pred_target_modelBiGRU})
    return self.result

  def smape(self,a, f):
    return 1/len(self.a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)

  def matrik_error(self):
    self.mse_modelBiGRU = mean_squared_error(self.result['Actual Value'], self.result['Bi-GRU'])
    self.mae_modelBiGRU = mean_absolute_error(self.result['Actual Value'], self.result['Bi-GRU'])
    #self.smape_ratio_cross_exMean = self.smape(first_strategy_result['Actual AQI'], first_strategy_result['AQI(R * Ex-Mean)'])
    self.r2_modelBiGRU = r2_score(self.result['Actual Value'], self.result['Bi-GRU'],multioutput='variance_weighted')

  def evaluation(self):
    print("MSE ",self.mse_modelBiGRU)
    print("MAE ",self.mae_modelBiGRU)
    #print("Smape Based ratio X exMean ",self.smape_ratio_cross_exMean)
    print("R2 ",self.r2_modelBiGRU)
    print("----------------------------------------------")

  def plotting(self):
    plt.plot(self.historymodelBiGRU.history['loss'], label = 'training loss')
    plt.plot(self.historymodelBiGRU.history['val_loss'], label = 'validation loss')
    plt.legend()
    return

  def run_all(self):
    self.tensor()
    self.model_BiGRU()
    self.predict()
    self.dataframe()
    self.matrik_error()
    self.evaluation()
    self.plotting()
    #self.train_target_plot()
    #self.train_eXfactor_plot()
    #self.train_ratio_plot()

#(epochs, batch_size, learning_rate,beta_1,beta_2)
biGRU = BiGRU(24,64,0.001,0.9,0.99)
biGRU.run_all()